create_model.py
2024-11-15 23:30:51.815351: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-15 23:30:53.053330: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-11-15 23:30:57.992972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "functional"
┌──────────────────────────────────────┬─────────────────────────────┬─────────────────┐
│ Layer (type)                         │ Output Shape                │         Param # │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ input_layer (InputLayer)             │ (None, 2548, 1)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ gru (GRU)                            │ (None, 2548, 512)           │         791,040 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 1304576)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 3)                   │       3,913,731 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 4,704,771 (17.95 MB)
 Trainable params: 4,704,771 (17.95 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/3
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 15s/step - accuracy: 0.6465 - loss: 120.1709
Epoch 1: val_accuracy improved from -inf to 0.91875, saving model to ./model.keras
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m730s←[0m 16s/step - accuracy: 0.6494 - loss: 118.8470 - val_accuracy: 0.9187 - val_loss: 10.5744 - learning_rate: 0.0010
Epoch 2/3
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 12s/step - accuracy: 0.9062 - loss: 11.7719
Epoch 2: val_accuracy improved from 0.91875 to 0.93906, saving model to ./model.keras
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m588s←[0m 13s/step - accuracy: 0.9068 - loss: 11.6708 - val_accuracy: 0.9391 - val_loss: 5.2549 - learning_rate: 9.0484e-04
Epoch 3/3
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 11s/step - accuracy: 0.9758 - loss: 1.6657
Epoch 3: val_accuracy improved from 0.93906 to 0.96250, saving model to ./model.keras
←[1m47/47←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m556s←[0m 12s/step - accuracy: 0.9757 - loss: 1.6692 - val_accuracy: 0.9625 - val_loss: 2.6347 - learning_rate: 8.1873e-04
Test Accuracy: 96.250%
←[1m20/20←[0m ←[32m━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m32s←[0m 2s/step
Classification Report:
----------------------
               precision    recall  f1-score   support

           0       0.96      0.96      0.96       205
           1       0.97      1.00      0.98       224
           2       0.96      0.93      0.94       211

    accuracy                           0.96       640
   macro avg       0.96      0.96      0.96       640
weighted avg       0.96      0.96      0.96       640
